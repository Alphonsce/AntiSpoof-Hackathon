{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "from shutil import copy\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "from data_utils import TestDataset, TrainDataset, genSpoof_list\n",
    "from eval.calculate_metrics import (calculate_aDCF_tdcf_tEER,\n",
    "                                    calculate_minDCF_EER_CLLR)\n",
    "from utils import create_optimizer, seed_worker, set_seed, str_to_bool\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_config: Dict, device: torch.device):\n",
    "    \"\"\"Define DNN model architecture\"\"\"\n",
    "    module = import_module(\"models.{}\".format(model_config[\"architecture\"]))\n",
    "    _model = getattr(module, \"Model\")\n",
    "    model = _model(model_config).to(device)\n",
    "    nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "    print(f\"no. model params:{(nb_params / 1000):.3f}k\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config/SEMAA_2021.conf\", \"r\") as f_json:\n",
    "    config = json.loads(f_json.read())\n",
    "model_config = config[\"model_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. model params:341.034k\n"
     ]
    }
   ],
   "source": [
    "model = get_model(model_config, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"exp_result/SEMAA_2021_ep100_bs24_rawboost/weights/epoch_0_0.013.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/a.varlamov/LJSpeech-1.1/wavs/LJ001-0011.wav\"\n",
    "audio, sr = torchaudio.load(path)\n",
    "\n",
    "audio = audio[:, :4 * sr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.cat([audio] * 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 45s, sys: 2min 14s, total: 11min\n",
      "Wall time: 5.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for elem in batch:\n",
    "    model(elem.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 20s, sys: 31.2 s, total: 1min 51s\n",
      "Wall time: 985 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.0000,  0.8879,  ..., -0.0000, -0.0000, -0.4481],\n",
       "         [ 0.8185,  0.5034,  0.0000,  ...,  0.0000, -1.0446,  0.0000],\n",
       "         [ 0.4865,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.6985],\n",
       "         ...,\n",
       "         [ 0.6315,  0.0000,  1.0028,  ...,  0.0000, -0.0000, -0.0000],\n",
       "         [ 2.0463,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.5176],\n",
       "         [ 0.1737,  0.0000,  0.0000,  ...,  0.0000, -1.3415, -0.1650]],\n",
       "        grad_fn=<MulBackward0>),\n",
       " tensor([[ 1.6370, -2.8142],\n",
       "         [ 1.6689, -1.4014],\n",
       "         [ 2.7145, -1.4595],\n",
       "         [ 2.0694, -2.4835],\n",
       "         [-0.5864, -0.3252],\n",
       "         [ 1.3176, -2.1768],\n",
       "         [ 1.3508, -1.1116],\n",
       "         [ 2.2993, -2.4627],\n",
       "         [ 3.7679, -2.9539],\n",
       "         [ 0.9321, -0.9999],\n",
       "         [ 2.3361, -2.4761],\n",
       "         [ 1.9903, -1.3204],\n",
       "         [ 1.6491, -1.5780],\n",
       "         [ 1.3913, -1.2798],\n",
       "         [ 3.3301, -2.9962],\n",
       "         [ 1.2729, -1.0937],\n",
       "         [ 1.4748, -1.5431],\n",
       "         [ 2.7387, -3.4770],\n",
       "         [ 1.7259, -3.9861],\n",
       "         [ 1.9127, -1.2276],\n",
       "         [ 2.5490, -3.3023],\n",
       "         [ 2.6205, -1.5230],\n",
       "         [ 4.0666, -2.7209],\n",
       "         [ 2.8982, -3.2056],\n",
       "         [ 7.3132, -6.6320],\n",
       "         [ 0.7606, -1.0175],\n",
       "         [ 2.1618, -2.1293],\n",
       "         [ 3.5911, -5.0326],\n",
       "         [ 4.6214, -4.4477],\n",
       "         [ 2.4412, -2.2469],\n",
       "         [ 1.6296, -1.1897],\n",
       "         [ 2.1179, -2.3172]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "batch = batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 672 ms, sys: 174 ms, total: 846 ms\n",
      "Wall time: 857 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for elem in batch:\n",
    "    model(elem.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 103 ms, sys: 4.74 ms, total: 107 ms\n",
      "Wall time: 106 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.2631,  0.4138,  0.0000,  ...,  0.0000, -0.0000,  0.4021],\n",
       "         [ 0.4781,  0.0000,  0.0000,  ..., -0.0465, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.4314,  2.2979,  ...,  0.3793, -1.2091,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.8540,  0.0000,  ..., -0.0000, -1.4942,  0.3136],\n",
       "         [ 0.0000,  0.0000,  0.9595,  ..., -0.0000, -0.0000,  0.3111],\n",
       "         [ 1.2072,  0.0000,  2.5564,  ..., -0.0000, -0.0000, -0.7329]],\n",
       "        device='cuda:5', grad_fn=<MulBackward0>),\n",
       " tensor([[ 1.6735,  0.1944],\n",
       "         [ 1.5841, -1.7493],\n",
       "         [ 1.7077, -2.1179],\n",
       "         [ 1.1154, -0.9293],\n",
       "         [ 2.7034, -2.4911],\n",
       "         [ 0.4057, -2.7683],\n",
       "         [ 0.3000, -0.4473],\n",
       "         [ 1.8537, -2.3073],\n",
       "         [ 4.0154, -3.2347],\n",
       "         [ 1.2749, -1.2102],\n",
       "         [ 2.0555, -2.0848],\n",
       "         [ 3.5232, -5.7168],\n",
       "         [ 1.8756, -2.3972],\n",
       "         [ 0.6575, -0.7447],\n",
       "         [ 2.3530, -3.0632],\n",
       "         [ 1.1080, -2.1790],\n",
       "         [ 2.8125, -1.1593],\n",
       "         [ 0.7529, -0.8296],\n",
       "         [ 2.8685, -2.4128],\n",
       "         [ 1.9515, -2.4888],\n",
       "         [ 0.5403, -1.0925],\n",
       "         [ 1.6975, -2.6133],\n",
       "         [ 3.2593, -3.1568],\n",
       "         [ 2.4783, -2.5281],\n",
       "         [ 4.8509, -5.7263],\n",
       "         [ 0.2018, -0.8261],\n",
       "         [ 2.4358, -3.2893],\n",
       "         [ 3.0731, -2.6943],\n",
       "         [ 2.5697, -2.7832],\n",
       "         [ 1.2365, -1.5921],\n",
       "         [ 1.5816, -2.0750],\n",
       "         [ 4.5623, -4.8862]], device='cuda:5', grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aasist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
