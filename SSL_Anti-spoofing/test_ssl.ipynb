{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from DPHuBERT.wav2vec2.model import wav2vec2_model\n",
    "import torch.nn as nn\n",
    "import fairseq\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"./DPHuBERT/checkpoints/DPHuBERT-sp0.75.pth\"\n",
    "ckpt = torch.load(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_hubert_model = wav2vec2_model(**ckpt[\"config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSLModel(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(SSLModel, self).__init__()\n",
    "\n",
    "        cp_path = \"./checkpoints_xlsr/xlsr2_300m.pt\"  # Change the pre-trained XLSR model path.\n",
    "        model, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task(\n",
    "            [cp_path]\n",
    "        )\n",
    "        self.model = model[0]\n",
    "        self.device = device\n",
    "        self.out_dim = 1024\n",
    "        return\n",
    "\n",
    "    def extract_feat(self, input_data):\n",
    "\n",
    "        # put the model to GPU if it not there\n",
    "        if (\n",
    "            next(self.model.parameters()).device != input_data.device\n",
    "            or next(self.model.parameters()).dtype != input_data.dtype\n",
    "        ):\n",
    "            self.model.to(input_data.device, dtype=input_data.dtype)\n",
    "            self.model.train()\n",
    "\n",
    "        if True:\n",
    "            # input should be in shape (batch, length)\n",
    "            if input_data.ndim == 3:\n",
    "                input_tmp = input_data[:, :, 0]\n",
    "            else:\n",
    "                input_tmp = input_data\n",
    "\n",
    "            # [batch, length, dim]\n",
    "            emb = self.model(input_tmp, mask=False, features_only=True)[\"x\"]\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/a.varlamov/LJSpeech-1.1/wavs/LJ001-0008.wav\"\n",
    "audio, sr = torchaudio.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.cat([audio] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 39325])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsr_model = SSLModel(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 122, 1024])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsr_model.extract_feat(batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 122, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_hubert_model.extract_features(batch)[0][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPHubertModel(nn.Module):\n",
    "    def __init__(self, device, behaviour=\"last-layer\", freeze=False):\n",
    "        '''\n",
    "        Args:\n",
    "            device: obvious...\n",
    "            behaviour: last-layer / weighted-sum\n",
    "            freeze: to freeze weights of the pre-train or not\n",
    "                for weighted-sum freezing will not let weights of sum train\n",
    "        '''\n",
    "        super(DPHubertModel, self).__init__()\n",
    "\n",
    "        ckpt_path = \"./DPHuBERT/checkpoints/DPHuBERT-sp0.75.pth\"\n",
    "        ckpt = torch.load(ckpt_path)\n",
    "        self.model = wav2vec2_model(**ckpt[\"config\"]).to(device)\n",
    "        self.device = device\n",
    "        self.out_dim = 768\n",
    "        self.n_layers = 12\n",
    "        self.behaviour = behaviour\n",
    "        \n",
    "        if behaviour == \"weighted-sum\":\n",
    "            self.sum_weights = nn.parameter.Parameter(torch.tensor([0.] * 9 + [0.5, 0.5, 0.5])).reshape(self.n_layers, 1, 1, 1)\n",
    "        \n",
    "        if freeze:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def extract_feat(self, input_data):\n",
    "\n",
    "        # put the model to GPU if it not there\n",
    "        if (\n",
    "            next(self.model.parameters()).device != input_data.device\n",
    "            or next(self.model.parameters()).dtype != input_data.dtype\n",
    "        ):\n",
    "            self.model.to(input_data.device, dtype=input_data.dtype)\n",
    "            self.model.train()\n",
    "\n",
    "        if True:\n",
    "            # input should be in shape (batch, length)\n",
    "            if input_data.ndim == 3:\n",
    "                input_tmp = input_data[:, :, 0]\n",
    "            else:\n",
    "                input_tmp = input_data\n",
    "\n",
    "            # [batch, length, dim]\n",
    "            if self.behaviour == \"last-layer\":\n",
    "                emb = self.model.extract_features(input_tmp)[0][-1]  # getting features from the last layer of transformer\n",
    "            elif self.behaviour == \"weighted-sum\":\n",
    "                all_layers_out = self.model.extract_features(input_tmp)[0][1:]\n",
    "                all_layers_out = torch.stack(all_layers_out)\n",
    "                emb = (all_layers_out * self.sum_weights).sum(dim=0)\n",
    "                return emb\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_hubert_model = DPHubertModel(\"cpu\", freeze=False, behaviour=\"weighted-sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = dp_hubert_model.extract_feat(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 2, 122, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(all_out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list = [torch.randn(2, 122, 768) for _ in range(12)]  # list of 12 tensors\n",
    "weights_tensor = torch.randn(12)  # 1D tensor with 12 elements\n",
    "\n",
    "# Convert list of tensors into a single tensor of shape [12, 2, 122, 768]\n",
    "tensor_stack = torch.stack(tensor_list)  # Shape: [12, 2, 122, 768]\n",
    "\n",
    "# Reshape weights_tensor to [12, 1, 1, 1] for broadcasting\n",
    "weights_tensor_reshaped = weights_tensor.view(12, 1, 1, 1)\n",
    "\n",
    "# Perform element-wise multiplication\n",
    "result = (tensor_stack * weights_tensor_reshaped).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 122, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl_aasist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
